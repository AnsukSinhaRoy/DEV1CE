{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "from data.data_loader import DataLoader\n",
    "import data.indicators as Indicators\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "parent_dir = Path().resolve().parent\n",
    "models_dir = parent_dir / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dfmain = DataLoader.load_data()\n",
    "df = dfmain.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perfect_signals(df, lookahead):\n",
    "    df = df.copy()\n",
    "    df['signals'] = np.nan  # Initialize with NaN for proper trend marking\n",
    "\n",
    "    for i in range(len(df) - lookahead):\n",
    "        future_prices = df['close'].iloc[i+1 : i+1+lookahead].values\n",
    "        if len(future_prices) > 0:\n",
    "            max_future_price = np.max(future_prices)\n",
    "            min_future_price = np.min(future_prices)\n",
    "\n",
    "            # If the price is near the lowest future price, mark an uptrend (1)\n",
    "            if df['close'].iloc[i] <= min_future_price + 0.1:\n",
    "                df.at[i, 'signals'] = 1  # Uptrend\n",
    "\n",
    "            # If the price is near the highest future price, mark a downtrend (0)\n",
    "            elif df['close'].iloc[i] >= max_future_price - 0.1:\n",
    "                df.at[i, 'signals'] = 0  # Downtrend\n",
    "\n",
    "    # **Propagate the trend signals forward**\n",
    "    df['signals'] = df['signals'].ffill().fillna(0)  # Fill NaN values with previous trend, default to 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = generate_perfect_signals(dfmain,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max Scaled features: ['RSI', 'slowk', 'slowd', 'ADX', 'Close_Relative']\n",
      "Standard Scaled features: ['open', 'shares', 'Log_Returns', 'MACD_hist', 'BB_middle', 'ATR', 'DC_middle', 'MACD', 'OBV', 'Sharpe_Ratio', 'DC_upper', 'Ichimoku_Kijun', 'Unnamed: 0', 'EMA_fast', 'Parabolic_SAR', 'low', 'Ichimoku_Senkou_A', 'EMA_slow', 'Ichimoku_Tenkan', 'close', 'Cumulative_Returns', 'MACD_signal', 'BB_upper', 'portfolio_value', 'ROC', 'CMF', 'DC_lower', 'BB_lower', 'Drawdown', 'high', 'Volume_SMA', 'volume', 'Ichimoku_Senkou_B', 'signals', 'Volatility', 'Norm_ATR', 'Volume_Threshold', 'Ulcer_Index']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_data(df, window_size=60):\n",
    "    \"\"\"Prepare dataset for deep learning models.\"\"\"\n",
    "    \n",
    "    # Drop missing values created by rolling window calculations\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Exclude datetime columns\n",
    "    df = df.select_dtypes(include=[np.number])  # Keep only numeric columns\n",
    "    \n",
    "    # Define MinMax and Standard scaling columns\n",
    "    min_max_cols = [\"RSI\", \"slowk\", \"slowd\", \"ADX\", \"Close_Relative\"]\n",
    "    standard_cols = list(set(df.columns) - set(min_max_cols))\n",
    "\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    standard_scaler = StandardScaler()\n",
    "\n",
    "    # Apply scaling only if the columns exist\n",
    "    if set(min_max_cols).issubset(df.columns):\n",
    "        df[min_max_cols] = min_max_scaler.fit_transform(df[min_max_cols])\n",
    "    \n",
    "    if set(standard_cols).issubset(df.columns):\n",
    "        df[standard_cols] = standard_scaler.fit_transform(df[standard_cols])\n",
    "\n",
    "    print(\"Min-Max Scaled features:\", min_max_cols)\n",
    "    print(\"Standard Scaled features:\", standard_cols)\n",
    "\n",
    "    # Convert into time-series sequences (shape: [samples, timesteps, features])\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        X.append(df.iloc[i:i+window_size].values)  # Last N timesteps\n",
    "        y.append(df[\"signals\"].iloc[i+window_size])  # Target trend (0 or 1)\n",
    "\n",
    "    return np.array(X), np.array(y), min_max_scaler, standard_scaler\n",
    "\n",
    "X, Y, MMS, SS = preprocess_data(df, window_size=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (386517, 10, 20)\n",
      "Testing Data Shape: (42947, 10, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Select features and target\n",
    "features = [\"EMA_slow\", \"EMA_fast\", \"RSI\", \"BB_upper\", \"BB_middle\", \"BB_lower\",\n",
    "            \"ATR\", \"MACD\", \"MACD_signal\", \"MACD_hist\", \"slowk\", \"slowd\",\n",
    "            \"ROC\", \"ADX\", \"DC_upper\", \"DC_lower\", \"DC_middle\", \"Volume_SMA\",\n",
    "            \"Volume_Threshold\", \"Volatility\"]  # Add more if needed\n",
    "\n",
    "target = \"signals\"\n",
    "\n",
    "# Drop NaN values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[features])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X, y = np.array(X_scaled), np.array(df[target])\n",
    "\n",
    "# Reshape X for LSTM (samples, timesteps, features)\n",
    "timesteps = 10  # Number of past periods to consider\n",
    "X_lstm = []\n",
    "y_lstm = []\n",
    "\n",
    "for i in range(len(X) - timesteps):\n",
    "    X_lstm.append(X[i:i+timesteps])  # Take `timesteps` periods of data\n",
    "    y_lstm.append(y[i+timesteps])  # Target at `t+timesteps`\n",
    "\n",
    "X_lstm, y_lstm = np.array(X_lstm), np.array(y_lstm)\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y_lstm, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Testing Data Shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12079/12079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6ms/step - accuracy: 0.6184 - loss: 0.6551 - val_accuracy: 0.6352 - val_loss: 0.6431\n",
      "Epoch 2/100\n",
      "\u001b[1m12079/12079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 6ms/step - accuracy: 0.6382 - loss: 0.6426 - val_accuracy: 0.6435 - val_loss: 0.6371\n",
      "Epoch 3/100\n",
      "\u001b[1m12079/12079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - accuracy: 0.6412 - loss: 0.6390 - val_accuracy: 0.6469 - val_loss: 0.6351\n",
      "Epoch 4/100\n",
      "\u001b[1m12079/12079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6ms/step - accuracy: 0.6451 - loss: 0.6353 - val_accuracy: 0.6481 - val_loss: 0.6323\n",
      "Epoch 5/100\n",
      "\u001b[1m12079/12079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 6ms/step - accuracy: 0.6488 - loss: 0.6324 - val_accuracy: 0.6531 - val_loss: 0.6292\n",
      "Epoch 6/100\n",
      "\u001b[1m12079/12079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6529 - loss: 0.6289"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Save the model for future use\u001b[39;00m\n\u001b[0;32m     31\u001b[0m model_path \u001b[38;5;241m=\u001b[39m models_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_trend_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:395\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    386\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    387\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    394\u001b[0m     )\n\u001b[1;32m--> 395\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    407\u001b[0m }\n\u001b[0;32m    408\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:483\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    482\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 483\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32me:\\Python\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"Create an LSTM model for trend classification.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=input_shape),  # First LSTM layer\n",
    "        Dropout(0.2),  # Regularization\n",
    "        LSTM(32, return_sequences=False),  # Second LSTM layer\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation=\"relu\"),  # Fully connected layer\n",
    "        Dense(1, activation=\"sigmoid\")  # Output layer (0 or 1)\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "# Build the model\n",
    "model = build_lstm_model(input_shape=(timesteps, len(features)))\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "# Save the model for future use\n",
    "\n",
    "model_path = models_dir / \"LSTM_model.h5\"\n",
    "model.save(str(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1343/1343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4371e-12\n",
      "Test Accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.semilogy(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.semilogy(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9445 - loss: 0.2738 - val_accuracy: 1.0000 - val_loss: 1.4372e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.5099e-04 - val_accuracy: 1.0000 - val_loss: 6.7723e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.5526e-05 - val_accuracy: 1.0000 - val_loss: 3.9302e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.4657e-05 - val_accuracy: 1.0000 - val_loss: 2.5653e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.9754e-05 - val_accuracy: 1.0000 - val_loss: 1.8303e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 2.3043e-05 - val_accuracy: 1.0000 - val_loss: 1.3676e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.7075e-05 - val_accuracy: 1.0000 - val_loss: 1.0786e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.3856e-05 - val_accuracy: 1.0000 - val_loss: 8.7130e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.1214e-05 - val_accuracy: 1.0000 - val_loss: 7.2197e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.4327e-06 - val_accuracy: 1.0000 - val_loss: 6.1289e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 7.9140e-06 - val_accuracy: 1.0000 - val_loss: 5.2672e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.4290e-06 - val_accuracy: 1.0000 - val_loss: 4.5525e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.1544e-06 - val_accuracy: 1.0000 - val_loss: 4.0079e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.2758e-06 - val_accuracy: 1.0000 - val_loss: 3.5574e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 4.8863e-06 - val_accuracy: 1.0000 - val_loss: 3.1919e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.6870e-06 - val_accuracy: 1.0000 - val_loss: 2.8815e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.9681e-06 - val_accuracy: 1.0000 - val_loss: 2.6231e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.6823e-06 - val_accuracy: 1.0000 - val_loss: 2.3951e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.3870e-06 - val_accuracy: 1.0000 - val_loss: 2.2008e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.2893e-06 - val_accuracy: 1.0000 - val_loss: 2.0257e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.9313e-06 - val_accuracy: 1.0000 - val_loss: 1.8758e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.7631e-06 - val_accuracy: 1.0000 - val_loss: 1.7342e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.4982e-06 - val_accuracy: 1.0000 - val_loss: 1.6155e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.3566e-06 - val_accuracy: 1.0000 - val_loss: 1.5114e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.2190e-06 - val_accuracy: 1.0000 - val_loss: 1.4160e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.0501e-06 - val_accuracy: 1.0000 - val_loss: 1.3291e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.9592e-06 - val_accuracy: 1.0000 - val_loss: 1.2521e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.8575e-06 - val_accuracy: 1.0000 - val_loss: 1.1806e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.7724e-06 - val_accuracy: 1.0000 - val_loss: 1.1146e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.6845e-06 - val_accuracy: 1.0000 - val_loss: 1.0544e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.5813e-06 - val_accuracy: 1.0000 - val_loss: 9.9935e-07\n",
      "Epoch 32/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.4805e-06 - val_accuracy: 1.0000 - val_loss: 9.4800e-07\n",
      "Epoch 33/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.4175e-06 - val_accuracy: 1.0000 - val_loss: 9.0087e-07\n",
      "Epoch 34/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.4165e-06 - val_accuracy: 1.0000 - val_loss: 8.5602e-07\n",
      "Epoch 35/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.3099e-06 - val_accuracy: 1.0000 - val_loss: 8.1489e-07\n",
      "Epoch 36/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.2401e-06 - val_accuracy: 1.0000 - val_loss: 7.7784e-07\n",
      "Epoch 37/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.1911e-06 - val_accuracy: 1.0000 - val_loss: 7.4264e-07\n",
      "Epoch 38/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.2030e-06 - val_accuracy: 1.0000 - val_loss: 7.0878e-07\n",
      "Epoch 39/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0829e-06 - val_accuracy: 1.0000 - val_loss: 6.7851e-07\n",
      "Epoch 40/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.8999e-07 - val_accuracy: 1.0000 - val_loss: 6.4954e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 1.0021e-06 - val_accuracy: 1.0000 - val_loss: 6.2236e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 9.8192e-07 - val_accuracy: 1.0000 - val_loss: 5.9634e-07\n",
      "Epoch 43/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 9.5340e-07 - val_accuracy: 1.0000 - val_loss: 5.7201e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 9.0636e-07 - val_accuracy: 1.0000 - val_loss: 5.4858e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.8835e-07 - val_accuracy: 1.0000 - val_loss: 5.2654e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 8.4795e-07 - val_accuracy: 1.0000 - val_loss: 5.0574e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.9872e-07 - val_accuracy: 1.0000 - val_loss: 4.8613e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 8.0703e-07 - val_accuracy: 1.0000 - val_loss: 4.6730e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 7.5147e-07 - val_accuracy: 1.0000 - val_loss: 4.4977e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 7.9189e-07 - val_accuracy: 1.0000 - val_loss: 4.3287e-07\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def build_optimized_lstm(input_shape, learning_rate=0.001, lstm_units=64, dropout_rate=0.2):\n",
    "    \"\"\"Builds an optimized LSTM model.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(units=lstm_units, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(units=lstm_units),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(units=1, activation=\"sigmoid\")  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=learning_rate), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Try different parameters\n",
    "optimized_model = build_optimized_lstm(input_shape=(timesteps, len(features)), learning_rate=0.0005, lstm_units=128, dropout_rate=0.3)\n",
    "\n",
    "# Train the new model\n",
    "history_opt = optimized_model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimized_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m \u001b[43moptimized_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_pred_prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)  \u001b[38;5;66;03m# Convert probabilities to 0/1 labels\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Compare actual vs predicted\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimized_model' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Make predictions\n",
    "y_pred_prob = optimized_model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to 0/1 labels\n",
    "\n",
    "# Compare actual vs predicted\n",
    "df_test = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred.flatten()})\n",
    "print(df_test.head(200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1239\n",
      "\n",
      "    accuracy                           1.00      1239\n",
      "   macro avg       1.00      1.00      1.00      1239\n",
      "weighted avg       1.00      1.00      1.00      1239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print performance metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
